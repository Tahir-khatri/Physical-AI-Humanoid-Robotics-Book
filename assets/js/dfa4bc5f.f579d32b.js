"use strict";(globalThis.webpackChunkbook_frontend=globalThis.webpackChunkbook_frontend||[]).push([[514],{8022(e){e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"bookSidebar":[{"type":"category","label":"Introduction","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/introduction/01-ros-2-overview","label":"1. The Nervous System","docId":"introduction/01-ros-2-overview","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/introduction/02-digital-twin-overview","label":"2. The Digital Twin","docId":"introduction/02-digital-twin-overview","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/introduction/03-isaac-perception-overview","label":"3. The AI Brain (Perception)","docId":"introduction/03-isaac-perception-overview","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/introduction/04-vla-capstone-overview","label":"4. The VLA Capstone","docId":"introduction/04-vla-capstone-overview","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: The Robotic Nervous System","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1/chapter-1","label":"ROS 2 Core Architecture","docId":"module-1/chapter-1","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1/chapter-2","label":"The AI Bridge (rclpy)","docId":"module-1/chapter-2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-1/chapter-3","label":"Humanoid Anatomy (URDF)","docId":"module-1/chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2/chapter-1","label":"Advanced Gazebo Physics","docId":"module-2/chapter-1","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2/chapter-2","label":"Immersive Rendering & HRI","docId":"module-2/chapter-2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-2/chapter-3","label":"Deep Sensor Simulation","docId":"module-2/chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3/chapter-1","label":"Isaac Sim & Synthetic Data","docId":"module-3/chapter-1","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3/chapter-2","label":"Isaac ROS & VSLAM","docId":"module-3/chapter-2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3/chapter-3","label":"Nav2 & Bipedal Path Planning","docId":"module-3/chapter-3","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4/chapter-1","label":"Voice-to-Action with Whisper","docId":"module-4/chapter-1","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4/chapter-2","label":"Cognitive Planning with LLMs","docId":"module-4/chapter-2","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4/chapter-3","label":"Capstone Project","docId":"module-4/chapter-3","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"intro":{"id":"intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes."},"introduction/01-ros-2-overview":{"id":"introduction/01-ros-2-overview","title":"ROS 2: The Robotic Nervous System","description":"Before a humanoid robot can take a single step, before it can process a single pixel from its camera, it needs a nervous system. In the world of modern robotics, that nervous system is the Robot Operating System (ROS), and specifically its second iteration, ROS 2. This chapter provides a high-level overview of ROS 2, establishing the foundational understanding of how a robot\'s disparate hardware and software components communicate to create a single, cohesive, and functional whole. It is the essential bedrock upon which all subsequent modules of this book\u2014from digital twins to advanced AI brains\u2014are built.","sidebar":"bookSidebar"},"introduction/02-digital-twin-overview":{"id":"introduction/02-digital-twin-overview","title":"The Digital Twin: Simulation Foundations","description":"In the realm of digital AI, an algorithm can be tested billions of times in a fraction of a second. An error might cause a program to crash, but the consequences are contained within the computer. In robotics, the stakes are infinitely higher. An error in a walking algorithm can cause a multi-million-dollar humanoid to fall and break. An error in a navigation algorithm could cause the robot to collide with a person. Developing and testing directly on physical hardware is slow, expensive, and dangerous. This is why the second pillar of modern robotics is the Digital Twin\u2014a high-fidelity simulation that acts as a virtual proxy for the real robot in a virtual world.","sidebar":"bookSidebar"},"introduction/03-isaac-perception-overview":{"id":"introduction/03-isaac-perception-overview","title":"The AI-Robot Brain: Isaac & Perception","description":"With a nervous system (ROS 2) and a virtual body (our Digital Twin) in place, we can now construct the core of our robot\'s autonomy the perception system. We will introduce the NVIDIA Isaac platform, a suite of tools specifically designed for building the high-performance, GPU-accelerated perception pipelines required by modern AI-powered robots. This is where raw sensor data transforms into meaningful understanding, enabling the robot to navigate, interact, and operate autonomously.","sidebar":"bookSidebar"},"introduction/04-vla-capstone-overview":{"id":"introduction/04-vla-capstone-overview","title":"The Convergence: VLA & Capstone","description":"We arrive at the final and most exciting stage of our journey: the convergence of all the systems we have built into a single, cognitive, autonomous whole. We have a nervous system (ROS 2), a virtual body (Digital Twin), and a hardware-accelerated perception system (Isaac ROS). Now, we will give our robot a true \\"mind\\" by integrating a Large Language Model (LLM) to act as a high-level cognitive planner. This is the domain of Vision-Language-Action (VLA) models, the frontier of Embodied AI research. This chapter provides a high-level overview of the concepts we will implement in Module 4, culminating in the capstone project. The goal is to build a system where you can give the robot a complex, natural language command like, \\"Clean the room,\\" and the robot can autonomously decompose that goal into a sequence of physical actions and execute them.","sidebar":"bookSidebar"},"module-1/chapter-1":{"id":"module-1/chapter-1","title":"Chapter 1: The ROS 2 Core Architecture","description":"Welcome to the foundational chapter of our journey into Physical AI and Humanoid Robotics. Before we can make our humanoid walk, talk, or think, we must first build its nervous system. In the world of modern robotics, the Robot Operating System (ROS) provides this fundamental framework. Specifically, we will be using ROS 2, a significant evolution of its predecessor, designed for everything from small, embedded projects to large, complex robot fleets.","sidebar":"bookSidebar"},"module-1/chapter-2":{"id":"module-1/chapter-2","title":"Chapter 2: The AI Bridge with rclpy","description":"In Chapter 1, we built the mental model for a robot\'s nervous system using ROS 2\'s core components: Nodes, Topics, and Services. Now, it\'s time to create the bridge that connects our high-level AI logic to this nervous system. This bridge is rclpy, the official ROS 2 client library for Python.","sidebar":"bookSidebar"},"module-1/chapter-3":{"id":"module-1/chapter-3","title":"Chapter 3: Humanoid Anatomy (URDF)","description":"We have established our robot\'s nervous system with ROS 2 and built the Python bridge to send commands. But what, exactly, are we commanding? A humanoid robot is a complex mechanical assembly of rigid bodies and articulating joints. For any part of the ROS 2 ecosystem to work with the robot\'s physical structure, it needs a standardized description of that structure. This is the role of the Unified Robot Description Format (URDF).","sidebar":"bookSidebar"},"module-2/chapter-1":{"id":"module-2/chapter-1","title":"Chapter 1: Advanced Gazebo Physics","description":"Welcome to the deep end of simulation. In Module 1, we defined our robot\'s body; now, we must define the world it lives in and the very laws of physics that govern it. A digital twin is only as valuable as its fidelity to the real world. For a humanoid robot, whose entire existence is a constant battle against gravity, a finely-tuned physics simulation is not a luxury\u2014it is the absolute prerequisite for any meaningful testing of walking, balancing, or manipulation algorithms.","sidebar":"bookSidebar"},"module-2/chapter-2":{"id":"module-2/chapter-2","title":"Chapter 2: Immersive Rendering & HRI with Unity","description":"While Gazebo provides the raw, functional physics simulation, the next frontier in creating a true digital twin lies in achieving photorealistic visuals and designing complex, intuitive human-robot interactions (HRI). This is where a professional game engine like Unity excels. By integrating our ROS 2-enabled robot into Unity, we can create environments that are not only physically accurate but also visually indistinguishable from reality, which is critical for training vision-based AI and developing safe, interactive behaviors.","sidebar":"bookSidebar"},"module-2/chapter-3":{"id":"module-2/chapter-3","title":"Chapter 3: Deep Sensor Simulation","description":"A digital twin\'s ultimate purpose is to serve as a high-fidelity proxy for a real-world robot. If an AI agent can be trained in simulation and then deployed to physical hardware with minimal performance degradation, the digital twin has succeeded. One of the greatest challenges in achieving this \\"sim-to-real\\" transfer is the \\"reality gap\\"\u2014the myriad differences between the clean, perfect world of the simulator and the noisy, unpredictable real world.","sidebar":"bookSidebar"},"module-3/chapter-1":{"id":"module-3/chapter-1","title":"Chapter 1: NVIDIA Isaac Sim & Synthetic Data","description":"Welcome to the cutting edge of robotics AI. In the previous modules, we established a nervous system with ROS 2 and explored the principles of creating a digital twin. Now, we ascend to the brain\u2014the perception and navigation systems that allow a robot to understand and move through its world. For this, we turn to the NVIDIA Isaac\u2122 ecosystem, a powerful, hardware-accelerated platform designed specifically for developing, training, and deploying AI-powered robots.","sidebar":"bookSidebar"},"module-3/chapter-2":{"id":"module-3/chapter-2","title":"Chapter 2: Isaac ROS & Hardware-Accelerated VSLAM","description":"In the previous chapter, we built a factory for generating photorealistic sensor data. Now, we must build the robot\'s brain that processes this data. For a mobile robot, the most fundamental perceptual ability is understanding where it is and what its environment looks like. This is the problem of Simultaneous Localization and Mapping (SLAM).","sidebar":"bookSidebar"},"module-3/chapter-3":{"id":"module-3/chapter-3","title":"Chapter 3: Nav2 & Bipedal Path Planning","description":"We have equipped our robot with a photorealistic world and a hardware-accelerated perception system. It can see and understand its environment. The final step in creating a truly autonomous agent is to give it the ability to navigate\u2014to move from point A to point B intelligently and without collisions. For this, we turn to Navigation 2 (Nav2), the standard navigation stack in ROS 2.","sidebar":"bookSidebar"},"module-4/chapter-1":{"id":"module-4/chapter-1","title":"Chapter 1: Voice-to-Action with OpenAI Whisper","description":"Welcome to the final module, where we give our robot its voice and a higher level of cognitive function. The ultimate goal of robotics is to create machines that can interact with humans and the world in a natural, intuitive way. The most natural form of human communication is speech. This chapter provides an exhaustive technical guide to building the first component of this system: a Voice-to-Action pipeline.","sidebar":"bookSidebar"},"module-4/chapter-2":{"id":"module-4/chapter-2","title":"Chapter 2: Cognitive Planning & LLM-to-ROS Orchestration","description":"In the previous chapter, we built a bridge from human speech to text. Now, we will build a bridge from text to intent. A simple command parser with keyword spotting is effective for basic, predefined commands, but it is brittle. It fails as soon as a user phrases a command in an unexpected way. To create a truly intelligent and flexible robot, we need a system that can understand the user\'s goal, not just recognize keywords.","sidebar":"bookSidebar"},"module-4/chapter-3":{"id":"module-4/chapter-3","title":"Chapter 3: Capstone - The Autonomous Humanoid","description":"This is the moment we have been building towards. Across three modules, we have assembled the essential components of an intelligent robot: a nervous system (ROS 2), a physical body in a realistic world (Gazebo/Unity), and a hardware-accelerated perception system (Isaac ROS). In this final module, we have given that system a voice and a cognitive planner. Now, we will put it all together.","sidebar":"bookSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template."},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed..."},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack)."},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features."},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs."},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French."}}}}')}}]);
# Implementation Plan: RAG Agent Backend

**Branch**: `013-rag-agent-backend` | **Date**: 2026-01-02 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `specs/013-rag-agent-backend/spec.md`

## Summary

This plan details the technical approach for building a RAG Agent backend using FastAPI and the OpenAI Agents SDK. The backend will expose API endpoints for a chatbot, retrieve relevant context from a Qdrant vector store, and use a Neon Serverless Postgres database for persisting chat session history.

## Technical Context

**Language/Version**: Python 3.11
**Primary Dependencies**: `fastapi`, `uvicorn`, `openai`, `qdrant-client`, `cohere`, `psycopg2-binary`, `python-dotenv`
**Storage**: Qdrant Cloud (Vector DB), Neon Serverless Postgres (Relational DB)
**Testing**: `pytest`, `httpx` (for API testing)
**Target Platform**: Any platform capable of running a Python backend server.
**Project Type**: Web Application (Backend API)
**Performance Goals**: Average response time for chat queries under 5 seconds.
**Constraints**: Must operate within the free tiers of all specified cloud services (Qdrant, Neon, Cohere, OpenAI).
**Scale/Scope**: Designed to serve a low-to-moderate number of concurrent users for a single book's RAG chatbot.

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

- [x] **Spec-Driven**: All work is traceable to `specs/013-rag-agent-backend/spec.md`.
- [x] **Grounding**: The agent's retrieval tool is designed to query book content from Qdrant, ensuring responses are grounded.
- [x] **Modernity**: The stack uses FastAPI, Qdrant, and Neon, aligning with modern, serverless principles.
- [x] **Constraints**: The solution is designed to work within the specified free-tier limitations.

## Project Structure

### Documentation (this feature)

```text
specs/013-rag-agent-backend/
├── plan.md              # This file
├── research.md          # Research on FastAPI/OpenAI/DB integration
├── data-model.md        # Postgres schema for chat history
├── quickstart.md        # Setup and execution guide
├── contracts/           # API contract definitions
└── tasks.md             # To be generated by /sp.tasks
```

### Source Code (repository root)

This feature adds a new `agent` sub-directory to the existing `backend` directory.

```text
backend/
├── agent/
│   ├── main.py          # FastAPI app, routes, and server logic
│   ├── agent.py         # OpenAI Agent setup and retrieval tool
│   └── database.py      # Functions for Postgres interaction
├── .env.example
├── main.py              # Ingestion script (from feature 011)
├── retrieve.py          # Validation script (from feature 012)
└── pyproject.toml
```

**Structure Decision**: A new `backend/agent/` directory is created to encapsulate all logic related to the RAG agent API. This cleanly separates the API service from the data ingestion and validation scripts, promoting modularity.

## Phase 0: Research

Technical decisions regarding the integration of FastAPI, OpenAI Agents SDK, Qdrant, and Neon Postgres have been researched and are documented in `research.md`.

- **Reference**: [research.md](./research.md)

## Phase 1: Design

### Data Model

The data model for storing chat sessions and messages in Postgres is defined in `data-model.md`.

- **Reference**: [data-model.md](./data-model.md)

### API Contracts

The API request/response models for the `/chat` and `/chat/contextual` endpoints are defined in `contracts/contracts.md`. These will be implemented as Pydantic models in FastAPI.

- **Reference**: [contracts/contracts.md](./contracts/contracts.md)

### High-Level Architecture

1.  **FastAPI Entrypoint (`agent/main.py`)**:
    -   Initializes the FastAPI application.
    -   Defines the `/chat` and `/chat/contextual` API endpoints.
    -   Handles incoming requests, extracting the question, session ID, and any context.

2.  **Database Interaction (`agent/database.py`)**:
    -   Contains functions to connect to the Neon Postgres database.
    -   Provides `get_or_create_session()`, `get_chat_history()`, and `add_message_to_history()` functions.
    -   Initializes the required `chat_sessions` and `chat_messages` tables if they don't exist.

3.  **Agent Logic (`agent/agent.py`)**:
    -   Defines the `QdrantRetriever` tool that the OpenAI Assistant can use. This tool will take a search query, embed it using Cohere, and query Qdrant to find relevant text chunks.
    -   Contains a function to initialize and run the OpenAI Assistant. This function will:
        -   Take the user's question and chat history as input.
        -   Pass the `QdrantRetriever` tool definition to the Assistant.
        -   Execute the agent run and return the final response.

4.  **Execution Flow**:
    -   A request hits an endpoint in `agent/main.py`.
    -   The endpoint uses `agent/database.py` to fetch history for the session.
    -   The endpoint calls the main agent function in `agent/agent.py`, passing the history and new question.
    -   The agent in `agent.py` decides to use its `QdrantRetriever` tool.
    -   The tool function executes, querying Qdrant and returning context.
    -   The agent uses the context to generate a final answer.
    -   The endpoint in `agent/main.py` saves the new messages to the database via `agent/database.py` and returns the response to the user.

### Quickstart Guide

A guide for setting up the environment, installing dependencies, and running the FastAPI server is available in `quickstart.md`.

- **Reference**: [quickstart.md](./quickstart.md)

## Complexity Tracking

No violations of the project constitution were identified. The complexity is moderate due to the integration of multiple services (FastAPI, OpenAI, Qdrant, Neon).